# Char-RNN
## Basic charater-level language model 
Basic-Char-RNN
## ACT charater-level language model
ACT-Char-RNN: Implement the paper [Adaptive Computation Time for Recurrent Neural Networks](https://arxiv.org/pdf/1603.08983v4.pdf) with TensorFlow. However, I get a reverse phenomenon contrast to the ACT paper. The neural network ponders less on space charecter than others. For example:
m 0.454589  2
a 0.427821  2
y 0.364154  2
  0.174726  2
w 0.415943  2
a 0.252345  3
n 0.416126  2
t 0.326544  3
  0.127796  2
t 0.144139  4
o 0.069154  7
  0.245744  2
m 0.101206  4
o 0.149854  3
v 0.172533  2
e 0.189886  3
  0.309559  2
t 0.016886  8
h 0.063482  7
e 0.145703  5
i 0.445629  2
r 0.194783  3
  0.220730  2
t 0.018884  6
e 0.151015  7
l 0.043927  4
e 0.107134  4
p 0.365345  2
h 0.489652  2
o 0.333370  2
n 0.131339  2
e 0.107761  3
s 0.473557  2
  0.127215  2
a 0.014068  4
  0.391733  2
l 0.103329  5
i 0.047037  3
t 0.010981  3
t 0.265462  3
l 0.097157  3
e 0.245089  3
  0.244892  2
c 0.297898  2
l 0.099785  3
o 0.326456  2
s 0.136414  2
e 0.060669  3
r 0.115891  3
  0.193604  2
t 0.177124  4
o 0.043886  6
